{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prediciendo con la intuición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](/files/images/knn_intro.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vecinos más cercanos (k-Nearest Neighbors o k-NN)\n",
    "\n",
    "- Se lo conoce también como Aprendizaje o Razonamiento Basado en Casos, o \"Lazy Learning\" (no hay cálculo alguno hasta la fase de clasificación)\n",
    "- El modelo no existe explícitamente (es de tipo no paramétrico)\n",
    "- El único parámetro es el k (número de vecinos a utilizar)\n",
    "- Es muy dependiente e inestable en k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo para k=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](/files/images/knn_sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forma de medir la distancia\n",
    "\n",
    "### Distancia de Minkowsky\n",
    "\n",
    "$$ L^p(x_j, x_q) = (\\sum_{i}|x_{j,i} - x_{q,i}|^p)^{\\frac{1}{p}} $$\n",
    "\n",
    "\n",
    "También conocida como distancia Euclidea (p=2) o de Manhattan (p=1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Se deben normalizar los datos !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Algunas alternativas:\n",
    "\n",
    "### k-NN con rechazasos:\n",
    "\n",
    "- Demanda algunas garantías para predecir, por ejemplo, que exista una mayoría de 75% sobre la clase predominante.\n",
    "- Si no se consigue se deja sin clasificar hasta que se consigan más datos o se utilice otro método.\n",
    "\n",
    "### k-NN de distancias medias:\n",
    "- Se calculan las distancias medias de todas las clases y se asigna la clase que tiene en total una distancia menor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusión\n",
    "\n",
    "### Es un método fácil de entender y de implementar pero puede presentar algunos problemas de performance. \n",
    "### En términos generales, podemos decir que funciona bien con muchos datos y pocas dimensiones.\n",
    "### Se lo puede utilizar en problemas de clasificación y de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](/files/images/knn_meme.jpeg)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
