{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Uno de los modelos más complejos y **poderosos**.\n",
    "\n",
    "Idea vieja, pero resucitada por disponibilidad de datos y hardware.\n",
    "\n",
    "Para aprendizaje supervisado, no supervisado, y por refuerzo. Un mundo de posibilidades..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... Nosotros nos vamos a centrar en aprendizaje **supervisado** (clasificación y regresión)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Por qué? Cuándo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Cuando modelos simples no funcionan...\n",
    "* ... y tenemos hardware y datos.\n",
    "* Cuando trabajamos con imágenes, video, audio y más.\n",
    "* Cuando alguien ya entrenó y publicó una red que hace lo que queremos, o muy parecido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Hype?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Repasemos: descenso por el gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/train.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/gradient_descent.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Repasemos: regresión logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/logistic_regression_function.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/sigmoid_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/logistic_regression_boundary_good_1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/logistic_regression_boundary_good_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Funciona siempre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# No linealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Necesitamos un modelo más complejo, una recta **nunca funcionaría**.\n",
    "\n",
    "Veamos entonces, **redes neuronales**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Neurona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Vagamente inspirada en neuronas reales.\n",
    "* N entradas, 1 salida\n",
    "* La salida sale de hacer una operación con las entradas y pesos internos.\n",
    "* ... O sea que es una **función**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/neuron_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Qué pasa si Act == Sigmoid?..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Es una **regresión logística**! Podemos entrenarla con **descenso por el gradiente**, para que clasifique cosas.\n",
    "\n",
    "Una neurona sola, ya podría ser entrenada y clasificar... cosas lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Y una red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Muchas neuronas juntas podrán hacer algo mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_two_neurons.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y si armamos ahora otro set de datos, con las salidas de estas dos neuronas y su clase?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_outputs_two_neurons.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y si intentamos ahora usar ese nuevo set de datos, para entrenar una tercer neurona?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_third_neuron.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/three_neurons.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/three_neurons_function.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Red neuronal!\n",
    "\n",
    "![](files/images/neural_network_1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Este es **un tipo** de red neuronal específico: Multi-Layer Perceptron, o **MLP**.\n",
    "\n",
    "Es una red \"feed forward\": las operaciones se hacen en una sola dirección, hacia adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/neural_network_1.svg)\n",
    "\n",
    "* Podemos agregar muchas capas, con muchas neuronas en cada capa.\n",
    "* Hay una **capa de entrada** y una **capa de salida**. Las demás son **capas ocultas**.\n",
    "* Se suele dibujar a las entradas como neuronas también, aunque no lo sean realmente.\n",
    "* Es demostrable que una sola capa oculta es suficiente para poder lograr cualquier función. El tema es cuántas neuronas, y qué tan fácil aprende eso.\n",
    "* Podemos tener muchas salidas si ponemos varias neuronas en la capa de salida!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dónde está el conocimiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/neural_network_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cómo encontramos esos pesos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nuestro viejo amigo, **descenso por el gradiente**.\n",
    "\n",
    "Aunque también hay otras opciones (como algoritmos genéticos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/neural_network_2.svg)\n",
    "\n",
    "Y las **derivadas** de esto?????\n",
    "\n",
    "Se puede. Es complejo. Por suerte las herramientas nos las resuelven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... pero hay un problema: **¿Cómo determinar la actualización de pesos de capas ocultas?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation\n",
    "<div><img src=\"files/images/backpropagation.gif\" width=\"50%\" style=\"float: right; margin: 10px;\" align=\"middle\"></div>\n",
    "\n",
    "Es un algoritmo que permite propagar la señal de error a las capas ocultas.\n",
    "\n",
    "Por ejemplo, un peso del final se modifica sin problemas. Un peso del inicio se modifica **teniendo en cuenta cómo se propaga el error del final a las salidas de esta capa**.\n",
    "\n",
    "No vamos a ver su detalle matemático. Las herramientas lo traen implementado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Hay que decidir unas cuantas cosas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cuántas **capas**? Cuántas **neuronas** en cada capa? Cómo son las **conexiones** entre capas?\n",
    "\n",
    "Esto se llama \"Arquitectura\" de nuestra red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pregunta difícil de responder: depende del caso, mirar cosas que hizo otra gente, etc.\n",
    "\n",
    "* Pocas? Podemos no lograr buen resultado.\n",
    "* Muchas? Podemos sobreentrenar, y puede ser muy lento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Qué función de **activación** en cada capa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lo habitual es:\n",
    "\n",
    "* Relu, Tanh o Sigmoidea en capas intermedias.\n",
    "* Sigmoidea en capa de salida de redes con una sola salida entre 0 y 1.\n",
    "* Softmax en capa de salida de redes con N salidas entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Qué variante de **decenso por el gradiente**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Normalmente \"adam\" anda bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Qué variante de función de **error**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lo habitual es:\n",
    "\n",
    "* Binary_crossentropy para redes con una sola salida entre 0 y 1.\n",
    "* Categorical_crossentropy para redes con N salidas entre 0 y 1.\n",
    "\n",
    "A veces puede hacer falta configurar \"pesos\" para los errores positivos y negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Y algunos consejos más\n",
    "\n",
    "* Normalizar las entradas.\n",
    "* Como siempre, entrenar y testear con sets separados. Las redes neuronales pueden overfitear muy fácil!\n",
    "* Probar cambios de a **una** cosa a la vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Técnica relacionada útil: dropout\n",
    "\n",
    "<div><img src=\"files/images/dropout.svg\" width=\"40%\" style=\"float: right; margin: 10px;\" align=\"middle\"></div>\n",
    "\n",
    "\n",
    "Capa que \"apaga\" conexiónes de forma aleatoria.\n",
    "\n",
    "\n",
    "**Para qué?**\n",
    "\n",
    "Para evitar que cada capa se \"memorice\" resultados que tiene que dar para determinados inputs (overfit interno y de la red en general)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Zoológico de redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "MLP es el tipo más común, pero hay **muchas** otras formas de neuronas.\n",
    "\n",
    "Principalmente lo que cambia es la **arquitectura de la red**, la forma en la que las neuronas están conectadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/zoo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Muy buen resumen de la utilidad de cada arquitectura!:\n",
    "\n",
    "[THE NEURAL NETWORK ZOO](http://www.asimovinstitute.org/neural-network-zoo/)\n",
    "\n",
    "Nosotros vamos a ver un poco de 3 de ellas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Esto es un poco loco..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/autoencoders.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenamos usando las entradas también como salidas! \n",
    "\n",
    "Ej: \n",
    "\n",
    "entrada=`[\"fisa\", 30, \"espadas\"]`\n",
    "\n",
    "salida=`[\"fisa\", 30, \"espadas\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Como la red se **achica en el medio**, entonces tiene que **comprimir la información de entrada** de alguna forma, para que termine siendo expresada en menos números.\n",
    "\n",
    "Pero como luego desde esos pocos números tiene que volver a generar las salidas originales, tiene que poder **descomprimir la información comprimida**.\n",
    "\n",
    "Termina aprendiendo dos redes juntas: una que **comprime** información, y otra que la **descomprime**... Nuestro propio algoritmo de compresión! \n",
    "\n",
    "Inentendible, pero que quizás funciona mejor para nnuestro problema, que los algoritmos genéricos de compresión.\n",
    "\n",
    "También se puede usar para **reducir dimensionalidad** de un set de datos (para visualizarlo, dárselo a modelos más simples, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes generadoras\n",
    "\n",
    "### Generative Adversarial Networks (GANs)\n",
    "\n",
    "### Generative Pre-trained Transformers (GPTs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Esto es **muy** loco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`\"The coolest idea in machine learning in the last twenty years\"`\n",
    "\n",
    "-- Yann LeCun\n",
    "\n",
    "`\"Pretty much all interesting AI approaches involve GANs in the middle\"`\n",
    "\n",
    "-- Eric Smith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/transfer_style.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/transfer_style2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/transfer_style_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/transfer_style3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/bag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/pix2pix_face.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/scene.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/obama_hilary.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fisa/venvs/ucse_ml_repo/lib/python3.8/site-packages/IPython/core/display.py:419: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"800\" height=\"500\" src=\"https://www.youtube.com/embed/b5AWhh6MYCg\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"800\" height=\"500\" src=\"https://www.youtube.com/embed/b5AWhh6MYCg\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_resolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_refill.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_objects.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_faces.png)\n",
    "\n",
    "https://www.whichfaceisreal.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/best_programming_language.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Incluso jugar todo un juego así!! Entendiendo contexto e historia!!!!!\n",
    "\n",
    "https://play.aidungeon.io/main/landing\n",
    "\n",
    "![](files/images/dungeon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://www.instagram.com/openaidalle/\n",
    "\n",
    "“Antique photo of a knight riding a T-Rex” \n",
    "\n",
    "![](files/images/dalle_trex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://www.instagram.com/openaidalle/\n",
    "\n",
    "“A turkey sandwich as a superhero saving the city from danger in the style of a comic”\n",
    "\n",
    "![](files/images/dalle_super_sandwich.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://www.instagram.com/openaidalle/\n",
    "\n",
    "\"A teddy bear on a skateboard in Times Square\" \n",
    "\n",
    "![](files/images/dalle_skate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "https://www.instagram.com/openaidalle/\n",
    "\n",
    "“An x-ray of a unicorn skull”\n",
    "\n",
    "![](files/images/dalle_xray.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"800\" height=\"500\" src=\"https://www.youtube.com/embed/fZSFNUT6iY8\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe width=\"800\" height=\"500\" src=\"https://www.youtube.com/embed/fZSFNUT6iY8\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# GANs: Cómo funcionan???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/gans.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La red **discriminadora** intenta predecir correctamente si sus entradas son un ejemplo real o un ejemplo generado.\n",
    "\n",
    "La red **generadora** trata de generar ejemplos que confundan a la red discriminadora, a partir de entradas (que pueden ser random, o algún tipo de dato relacionado. Ej: dibujo a mano)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Primero entrenamos un poco la red **discriminadora**, hasta que sepa reconocer bien la cosa que queremos generar después (ej: fotos de perros vs fotos de no-perros).\n",
    "\n",
    "Luego empezamos a generar ejemplos con la **generadora**, y se los pasamos a la **discriminadora**. Cuanto mejor prediga la discriminadora, **más error** le devolvemos a la generadora.\n",
    "\n",
    "Seguimos entrenando ambas redes **a la vez**, que a partir de ahora **compiten** (una por detectar bien perros reales, la otra por generar perros que parezcan reales)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MAGIA\n",
    "\n",
    "![](files/images/magic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# GPTs: Cómo funcionan???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Es un concepto **muy** avanzado para lo que llegamos a cubrir en la materia. Pero algunas generalidades:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Language models para generación de texto (next token prediction, seq2seq, ...)\n",
    "- Redes recurrentes... y el problema de los gradientes (recordar a largo plazo).\n",
    "- LSTMs... mejor recordando a largo plazo, pero igual limitado.\n",
    "- Transformers! All you need is attention. Ya no recurrentes, ver todo y decidir dónde enfocarse (GPT3 = 2048 words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Convolucionales\n",
    "\n",
    "## Motivación\n",
    "\n",
    "*Un repaso de como se veria una red Densa*\n",
    "\n",
    "<div><img src=\"images/mnist_multilayer.png\" width=\"400\" style=\"float: left; margin: 10px;\"></div>\n",
    "\n",
    "<div style=\"float: left; margin: 10px;\">\n",
    "    <ul>\n",
    "      <li>¿Cuántos pesos tiene cada neurona?</li>\n",
    "      <li>¿Se comparte información entre distintas ubicaciones de la imagen?</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div style=\"clear:both;\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Otra forma de interpretar los layers intermedios\n",
    "\n",
    "### Feature maps\n",
    "\n",
    "*Podemos pensarlo como neuronas que se activan con determinada lógica, que siguen la posición espacial de la imagen original*\n",
    "\n",
    "<div><img src=\"images/feature_maps.png\" width=\"600\" style=\"margin: 10px;\"></div>\n",
    "\n",
    "* Interesa mantener información espacial y destacar alguna propiedad particular\n",
    "* Interesa ir condensando información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ¿Cómo funciona la operación de convolución?\n",
    "\n",
    "<div><img src=\"images/conv_explanation.jpg\" width=\"50%\" style=\"float: left;\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1 canal\n",
    "\n",
    "![](files/images/conv_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3 canales, 2 filtros\n",
    "\n",
    "![](files/images/conv_calculation.png)\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Respecto de los problemas planteados originalmente\n",
    "\n",
    "### Gran cantidad de pesos\n",
    "\n",
    "* Si suponemos imagenes de 227x227x3, **cada neurona** de un feature map tendría 154.588 pesos para aprender\n",
    "* Al conectar las neuronas con una **porción** (receptive field) de la imagen de entrada se reduce drásticamente ese número\n",
    " * Por ejemplo, si cada neurona se conecta con una porción de 11x11, los pesos de esa neurona serían solo 364 (11x11x3 + 1)\n",
    "* Ese conjunto de pesos se denomina **filtro** y es lo que se **aprende** cuando entrenamos\n",
    "* Al convolucionar un filtro sobre la imagen de entrada obtenemos un **feature map**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Respecto de los problemas planteados originalmente\n",
    "\n",
    "### Información espacial compartida\n",
    "\n",
    "* Este problema se soluciona al utilizar siempre el mismo \"conjunto de pesos\" (a.k.a. **filtro**) para generar el feature map.\n",
    "\n",
    "Este hecho vuelve a reducir el número de parametros. Siguiendo el ejemplo anterior, si queremos que nuestros feature maps esten compuestos de 81 neuronas cada uno (9x9), sin compartir pesos tendriamos 364 * 81 = 29.484 pesos. \n",
    "\n",
    "Compartiendo los parámetros nos quedamos con solo 364 pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Parámetros y conceptos más comunes\n",
    "\n",
    "* **Input size W**: el tamaño de la entrada\n",
    "* **filters:** cantidad de filtros \n",
    "* **kernel_size F:** tamaño del kernel; se establece el ancho y alto, la profundidad depende de las entradas\n",
    "* **strides S:** la cantidad de pasos que muevo el kernel\n",
    "* **padding P:** agrega ceros en los bordes para mantener el tamaño original\n",
    "* **activation:** función de activación aplicada ``pixel a pixel``\n",
    "\n",
    "La cantidad de neuronas de salida es **(W - F + 2P)/S + 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pooling\n",
    "\n",
    "<div><img src=\"images/max_pooling.png\" width=\"30%\" style=\"float: left;\"></div>\n",
    "\n",
    "\n",
    "* Se usan para reducir la cantidad de parametros (2 stride, kernel de 2, 2 reduce a 25% la cantidad de parametros)\n",
    "* Hace mas complicado el sobreentrenamiento\n",
    "* No hay aprendizaje (operación fija)\n",
    "* Trabaja de forma independiente en cada profundidad. Ej: Input=(4, 4, 3) F=2, S=2, Output=(2, 2, 3)\n",
    "\n",
    "La versión más común es max pooling\n",
    "\n",
    "<div style=\"clear:both;\"></div>\n",
    "\n",
    "http://textminingonline.com/dive-into-tensorflow-part-v-deep-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Una red completa\n",
    "\n",
    "En algún momento, aplanamos la disposición de las neuronas para obtener un vector y continuar con una red fully connected convencional..\n",
    "\n",
    "<div><img src=\"images/neural_network_complete.png\" width=\"100%\" style=\"float: left;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Las convoluciones pueden terminar aprendiendo **\"features\"** de la imagen **de a poco**, desde conceptos más simples a más complejos.\n",
    "\n",
    "Ej:primer convolución reconoce tipo de terreno en base a pixeles (planta, agua, cemento, arena). La siguiente convolución reconoce ciudad/playa/bosque/desierto en base a los tipos de terreno y su posición en la salida de la capa anterior (ej: agua + arena = playa). La siguiente convolución reconoce la región del país, en base a cuántas playas, bosques, ciudades, etc ve en las salidas de la anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Son **muy** efectivas para trabajar con imágenes. El estándar hoy en día.\n",
    "* Son muy pesadas de calcular.\n",
    "* Implica determinar cosas nuevas: qué tamaño tienen los kernels, cuántas convoluciones, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Deep learning?\n",
    "\n",
    "*The hierarchy of concepts enables the computer to learn complicated concepts bybuilding them out of simpler ones. If we draw a graph showing how these concepts are built on top of each other, the graph is deep, with many layers. For this reason,we call this approach to AI deep learning.*\n",
    "\n",
    "\n",
    "**Goodfellow et al 2016**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transfer Learning\n",
    "\n",
    "## Qué es?\n",
    "\n",
    "* Tomar un modelo entrenado para la tarea *A* y reutilizarlo para hacer la tarea *B*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Para que?\n",
    "\n",
    "* Principalmente, para evitar conseguir y/o etiquetar un dataset \n",
    "* Beneficio adicional, nos ahorramos mucho poder de cómputo en el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cómo?\n",
    "\n",
    "* Buscamos un modelo entrenado \n",
    "* Reemplazamos las capas finales, frizamos las iniciales y entrenamos\n",
    "* A medida que el aprendizaje queda \"estancado\" podemos comenzar a des-frizar capas del final para ajustar mejor el descubrimiento de features (a este proceso se lo conoce como **fine tuning**\n",
    "\n",
    "<div><img src=\"images/transfer_learning.jpg\" width=\"75%\" style=\"float: center;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Synthetic data generation\n",
    "\n",
    "## Qué es?\n",
    "\n",
    "* Generar ejemplos a partir de ejemplos existentes\n",
    "\n",
    "## Para qué?\n",
    "\n",
    "* Para evitar sobre-entrenamiento\n",
    "\n",
    "## Como?\n",
    "\n",
    "* Aplicando algunas operaciones sobre los datos de entrada \n",
    "\n",
    "Para investigar un poco...(https://keras.io/api/preprocessing/image/#imagedatagenerator-class)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
