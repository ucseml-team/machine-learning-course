{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Uno de los modelos más complejos y **poderosos**.\n",
    "\n",
    "Idea vieja, pero resucitada por disponibilidad de datos y hardware.\n",
    "\n",
    "Para aprendizaje supervisado, no supervisado, y por refuerzo. Un mundo de posibilidades..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... Nosotros nos vamos a centrar en aprendizaje **supervisado** (clasificación y regresión)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Por qué? Cuándo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Cuando modelos simples no funcionan...\n",
    "* ... y tenemos hardware y datos.\n",
    "* Cuando trabajamos con imágenes.\n",
    "* Cuando alguien ya entrenó y publicó una red que hace lo que queremos, o muy parecido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Hype?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Repasemos: descenso por el gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/train.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/gradient_descent.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/line_function.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/predict.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Repasemos: regresión logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/logistic_regression_function.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/sigmoid_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/logistic_regression_boundary_good_1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/logistic_regression_boundary_good_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/logistic_regression_function_colorized.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Funciona siempre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# No linearidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Necesitamos un modelo más complejo, una recta **nunca funcionaría**.\n",
    "\n",
    "Veamos entonces, **redes neuronales**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Neurona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Vagamente inspirada en neuronas reales.\n",
    "* N entradas, 1 salida\n",
    "* La salida sale de hacer una operación con las entradas y pesos internos.\n",
    "* ... O sea que es una **función**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/neuron_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Qué pasa si Act == Sigmoid?..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Es una **regresión logística**! Podemos entrenarla con **descenso por el gradiente**, para que clasifique cosas.\n",
    "\n",
    "Una neurona sola, ya podría ser entrenada y clasificar... cosas lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Y una red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Muchas neuronas juntas podrán hacer algo mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_two_neurons.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y si armamos ahora otro set de datos, con las salidas de estas dos neuronas y su clase?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_outputs_two_neurons.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y si intentamos ahora usar ese nuevo set de datos, para entrenar una tercer neurona?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_third_neuron.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_third_neuron.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/three_neurons.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/three_neurons_function.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Red neuronal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/neural_network_1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Este es **un tipo** de red neuronal específico: Multi-Layer Perceptron, o **MLP**.\n",
    "\n",
    "Es una red \"feed forward\": las operaciones se hacen en una sola dirección, hacia adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Podemos agregar muchas capas, con muchas neuronas en cada capa.\n",
    "* Hay una **capa de entrada** y una **capa de salida**. Las demás son **capas ocultas**.\n",
    "* Se suele dibujar a las entradas como neuronas también, aunque no lo sean realmente.\n",
    "* Es demostrable que una sola capa oculta es suficiente para poder lograr cualquier función. El tema es cuántas neuronas, y qué tan fácil aprende eso.\n",
    "* Podemos tener muchas salidas si ponemos varias neuronas en la capa de salida!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dónde está el conocimiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/neural_network_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cómo encontramos esos pesos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nuestro viejo amigo, **descenso por el gradiente**.\n",
    "\n",
    "Aunque también hay otras opciones (como agoritmos genéticos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y las **derivadas** de esto?????\n",
    "\n",
    "Se puede. Es complejo. Por suerte las herramientas nos las resuelven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... pero hay un problema. Si tocamos un peso de una neurona de atrás, eso también está afectando a todas las siguientes neuronas! Eso altera todos los cálculos, y hace que no funcione el descenso por el gradiente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Es un algoritmo que permite calcular el **cambio que hay que hacer en cada peso**, teniendo en cuenta su **relación con los pesos siguientes y el resultado**.\n",
    "\n",
    "Por ejemplo, un peso del final se modifica sin problemas. Un peso del inicio se modifica **teniendo en cuenta cómo influye a lo que hay después de él**.\n",
    "\n",
    "No vamos a ver su detalle matemático. Las herramientas lo traen implementado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Hay que decidir unas cuantas cosas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cuántas **capas**? Cuántas **neuronas** en cada capa? Cómo son las **conexiones** entre capas?\n",
    "\n",
    "Esto se llama \"Arquitectura\" de nuestra red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pregunta difícil de responder: depende del caso, mirar cosas que hizo otra gente, etc.\n",
    "\n",
    "* Pocas? Podemos no lograr buen resultado.\n",
    "* Muchas? Podemos sobreentrenar, y puede ser muy lento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Qué función de **activación** en cada capa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lo habitual es:\n",
    "\n",
    "* Relu, Tanh o Sigmoidea en capas intermedias.\n",
    "* Sigmoidea en capa de salida de redes con una sola salida entre 0 y 1.\n",
    "* Softmax en capa de salida de redes con N salidas entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Qué variante de **decenso por el gradiente**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Normalmente \"adam\" anda bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Qué variante de función de **error**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lo habitual es:\n",
    "\n",
    "* Binary_crossentropy para redes con una sola salida entre 0 y 1.\n",
    "* Categorical_crossentropy para redes con N salidas entre 0 y 1.\n",
    "\n",
    "A veces puede hacer falta configurar \"pesos\" para los errores positivos y negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Y algunos consejos más\n",
    "\n",
    "* Normalizar las entradas.\n",
    "* Como siempre, entrenar y testear con sets separados. Las redes neuronales pueden overfitear muy fácil!\n",
    "* Probar cambios de a **una** cosa a la vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Técnica relacionada útil: dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/dropout.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Capa que \"apaga\" conexiónes de forma aleatoria.\n",
    "\n",
    "\n",
    "**Para qué?**\n",
    "\n",
    "Para evitar que cada capa se \"memorice\" resultados que tiene que dar para determinados inputs (overfit interno y de la red en general)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Zoológico de redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "MLP es el tipo más común, pero hay **muchas** otras formas de neuronas.\n",
    "\n",
    "Principalmente lo que cambia es la **arquitectura de la red**, la forma en la que las neuronas están conectadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/zoo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Muy buen resumen de la utilidad de cada arquitectura!:\n",
    "\n",
    "[THE NEURAL NETWORK ZOO](http://www.asimovinstitute.org/neural-network-zoo/)\n",
    "\n",
    "Nosotros vamos a ver un poco de 3 de ellas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Esto es un poco loco..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/autoencoders.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenamos usando las entradas también como salidas! \n",
    "\n",
    "Ej: \n",
    "\n",
    "entrada=`[\"fisa\", 30, \"espadas\"]`\n",
    "\n",
    "salida=`[\"fisa\", 30, \"espadas\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Como la red se **achica en el medio**, entonces tiene que **comprimir la información de entrada** de alguna forma, para que termine siendo expresada en menos números.\n",
    "\n",
    "Pero como luego desde esos pocos números tiene que volver a generar las salidas originales, tiene que poder **descomprimir la información comprimida**.\n",
    "\n",
    "Termina aprendiendo dos redes juntas: una que **comprime** información, y otra que la **descomprime**... Nuestro propio algoritmo de compresión! \n",
    "\n",
    "Inentendible, pero que quizás funciona mejor para nnuestro problema, que los algoritmos genéricos de compresión.\n",
    "\n",
    "También se puede usar para **reducir dimensionalidad** de un set de datos (para visualizarlo, dárselo a modelos más simples, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Esto es **muy** loco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/transfer_style.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/pix2pix_face.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/obama_hilary.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_resolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_refill.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_objects.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_faces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cómo funcionan???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/gans.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La red **discriminadora** intenta predecir correctamente si sus entradas son un ejemplo real o un ejemplo generado.\n",
    "\n",
    "La red **generadora** trata de generar ejemplos que confundan a la red discriminadora, a partir de entradas (que pueden ser random, o algún tipo de dato relacionado. Ej: dibujo a mano)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Primero entrenamos un poco la red **discriminadora**, hasta que sepa reconocer bien la cosa que queremos generar después (ej: fotos de perros vs fotos de no-perros).\n",
    "\n",
    "Luego empezamos a generar ejemplos con la **generadora**, y se los pasamos a la **discriminadora**. Cuanto mejor prediga la discriminadora, **más error** le devolvemos a la generadora.\n",
    "\n",
    "Seguimos entrenando ambas redes **a la vez**, que a partir de ahora **compiten** (una por detectar bien perros reales, la otra por generar perros que parezcan reales)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MAGIA\n",
    "\n",
    "![](files/images/magic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Convolucionales\n",
    "\n",
    "## Motivación\n",
    "\n",
    "*Un repaso de como se veria una red Densa*\n",
    "\n",
    "<div><img src=\"images/mnist_multilayer.png\" width=\"400\" style=\"float: left; margin: 10px;\"></div>\n",
    "\n",
    "<div style=\"float: left; margin: 10px;\">\n",
    "    <ul>\n",
    "      <li>¿Cuántos pesos tiene cada neurona?</li>\n",
    "      <li>¿Se comparte información entre distintas ubicaciones de la imagen?</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div style=\"clear:both;\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Otra forma de interpretar los layers intermedios\n",
    "\n",
    "### Feature maps\n",
    "\n",
    "*Podemos pensarlo como neuronas que se se activan con determinada lógica, que siguen la posición espacial de la imagen original*\n",
    "\n",
    "<div><img src=\"images/feature_maps.png\" width=\"600\" style=\"margin: 10px;\"></div>\n",
    "\n",
    "* Interesa mantener información espacial y destacar alguna propiedad particular\n",
    "* Interesa ir condensando información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ¿Cómo funciona la operación de convolución?\n",
    "\n",
    "<div><img src=\"images/conv_explanation.jpg\" width=\"50%\" style=\"float: left;\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1 canal\n",
    "\n",
    "![](files/images/conv_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3 canales, 2 filtros\n",
    "\n",
    "![](files/images/conv_calculation.png)\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Respecto de los problemas planteados originalmente\n",
    "\n",
    "### Gran cantidad de pesos\n",
    "\n",
    "* Si suponemos imagenes de 227x227x3, **cada neurona** de un feature map tendría 154.588 pesos para aprender\n",
    "* Al conectar las neuronas con una **porción** (receptive field) de la imagen de entrada se reduce drásticamente ese número\n",
    " * Por ejemplo, si cada neurona se conecta con una porción de 11x11, los pesos de esa neurona serían solo 364 (11x11x3 + 1)\n",
    "* Ese conjunto de pesos se denomina **filtro** y es lo que se **aprende** cuando entrenamos\n",
    "* Al convolucionar un filtro sobre la imagen de entrada obtenemos un **feature map**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Respecto de los problemas planteados originalmente\n",
    "\n",
    "### Información espacial compartida\n",
    "\n",
    "* Este problema se soluciona al utilizar siempre el mismo \"conjunto de pesos\" (a.k.a. **filtro**) para generar el feature map.\n",
    "\n",
    "Este hecho vuelve a reducir el número de parametros. Siguiendo el ejemplo anterior, si queremos que nuestros feature maps esten compuestos de 81 neuronas cada uno (9x9), sin compartir pesos tendriamos 364 * 81 = 29.484 pesos. \n",
    "\n",
    "Compartiendo los parámetros nos quedamos con solo 364 pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Parámetros y conceptos más comunes\n",
    "\n",
    "* **Input size W**: el tamaño de la entrada\n",
    "* **filters:** cantidad de filtros \n",
    "* **kernel_size F:** tamaño del kernel; se establece el ancho y alto, la profundidad depende de las entradas\n",
    "* **strides S:** la cantidad de pasos que muevo el kernel\n",
    "* **padding P:** agrega ceros en los bordes para mantener el tamaño original\n",
    "* **activation:** función de activación aplicada ``pixel a pixel``\n",
    "\n",
    "La cantidad de neuronas de salida es **(W - F + 2P)/S + 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pooling\n",
    "\n",
    "<div><img src=\"images/max_pooling.png\" width=\"30%\" style=\"float: left;\"></div>\n",
    "\n",
    "\n",
    "* Se usan para reducir la cantidad de parametros (2 stride, kernel de 2, 2 reduce a 25% la cantidad de parametros)\n",
    "* Hace mas complicado el sobreentrenamiento\n",
    "* No hay aprendizaje (operación fija)\n",
    "* Trabaja de forma independiente en cada profundidad. Ej: Input=(4, 4, 3) F=2, S=2, Output=(2, 2, 3)\n",
    "\n",
    "La versión más común es max pooling\n",
    "\n",
    "<div style=\"clear:both;\"></div>\n",
    "\n",
    "http://textminingonline.com/dive-into-tensorflow-part-v-deep-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Una red completa\n",
    "\n",
    "En algún momento, aplanamos la disposición de las neuronas para obtener un vector y continuar con aun red full connected convencional..\n",
    "\n",
    "<div><img src=\"images/neural_network_complete.png\" width=\"100%\" style=\"float: left;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Las convoluciones pueden terminar aprendiendo **\"features\"** de la imagen **de a poco**, desde conceptos más simples a más complejos.\n",
    "\n",
    "Ej:primer convolución reconoce tipo de terreno en base a pixeles (planta, agua, cemento, arena). La siguiente convolución reconoce ciudad/playa/bosque/desierto en base a los tipos de terreno y su posición en la salida de la capa anterior (ej: agua + arena = playa). La siguiente convolución reconoce la región del país, en base a cuántas playas, bosques, ciudades, etc ve en las salidas de la anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Son **muy** efectivas para trabajar con imágenes. El estándar hoy en día.\n",
    "* Son muy pesadas de calcular.\n",
    "* Implica determinar cosas nuevas: qué tamaño tienen los kernels, cuántas convoluciones, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Deep learning?\n",
    "\n",
    "*The hierarchy of concepts enables the computer to learn complicated concepts bybuilding them out of simpler ones. If we draw a graph showing how these concepts are built on top of each other, the graph is deep, with many layers. For this reason,we call this approach to AI deep learning.*\n",
    "\n",
    "\n",
    "**Goodfellow et al 2016**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
