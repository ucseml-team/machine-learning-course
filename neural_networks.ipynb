{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Uno de los modelos más complejos y **poderosos**.\n",
    "\n",
    "Idea vieja, pero resucitada por disponibilidad de datos y hardware.\n",
    "\n",
    "Para aprendizaje supervisado, no supervisado, y por refuerzo. Un mundo de posibilidades..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... Nosotros nos vamos a centrar en aprendizaje **supervisado** (clasificación y regresión)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Por qué? Cuándo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Cuando modelos simples no funcionan...\n",
    "* ... y tenemos hardware y datos.\n",
    "* Cuando trabajamos con imágenes.\n",
    "* Cuando alguien ya entrenó y publicó una red que hace lo que queremos, o muy parecido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Hype?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Repasemos: descenso por el gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/train.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/gradient_descent.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/line_function.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/predict.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Repasemos: regresión logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/logistic_regression_function.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/sigmoid_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/logistic_regression_boundary_good_1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/logistic_regression_boundary_good_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/logistic_regression_function_colorized.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Funciona siempre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# No linearidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Necesitamos un modelo más complejo, una recta **nunca funcionaría**.\n",
    "\n",
    "Veamos entonces, **redes neuronales**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Neurona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Vagamente inspirada en neuronas reales.\n",
    "* N entradas, 1 salida\n",
    "* La salida sale de hacer una operación con las entradas y pesos internos.\n",
    "* ... O sea que es una **función**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/neuron_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Qué pasa si Act == Sigmoid?..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Es una **regresión logística**! Podemos entrenarla con **descenso por el gradiente**, para que clasifique cosas.\n",
    "\n",
    "Una neurona sola, ya podría ser entrenada y clasificar... cosas lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Y una red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Muchas neuronas juntas podrán hacer algo mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_two_neurons.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y si armamos ahora otro set de datos, con las salidas de estas dos neuronas y su clase?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_outputs_two_neurons.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y si intentamos ahora usar ese nuevo set de datos, para entrenar una tercer neurona?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_third_neuron.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/non_linear_clasification_third_neuron.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/three_neurons.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/three_neurons_function.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Red neuronal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/neural_network_1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Este es **un tipo** de red neuronal específico: Multi-Layer Perceptron, o **MLP**.\n",
    "\n",
    "Es una red \"feed forward\": las operaciones se hacen en una sola dirección, hacia adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Podemos agregar muchas capas, con muchas neuronas en cada capa.\n",
    "* Hay una **capa de entrada** y una **capa de salida**. Las demás son **capas ocultas**.\n",
    "* Se suele dibujar a las entradas como neuronas también, aunque no lo sean realmente.\n",
    "* Es demostrable que una sola capa oculta es suficiente para poder lograr cualquier función. El tema es cuántas neuronas, y qué tan fácil aprende eso.\n",
    "* Podemos tener muchas salidas si ponemos varias neuronas en la capa de salida!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dónde está el conocimiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/neural_network_2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cómo encontramos esos pesos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nuestro viejo amigo, **descenso por el gradiente**.\n",
    "\n",
    "Aunque también hay otras opciones (como agoritmos genéticos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Y las **derivadas** de esto?????\n",
    "\n",
    "Se puede. Es complejo. Por suerte las herramientas nos las resuelven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... pero hay un problema. Si tocamos un peso de una neurona de atrás, eso también está afectando a todas las siguientes neuronas! Eso altera todos los cálculos, y hace que no funcione el descenso por el gradiente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Es un algoritmo que permite calcular el **cambio que hay que hacer en cada peso**, teniendo en cuenta su **relación con los pesos siguientes y el resultado**.\n",
    "\n",
    "Por ejemplo, un peso del final se modifica sin problemas. Un peso del inicio se modifica **teniendo en cuenta cómo influye a lo que hay después de él**.\n",
    "\n",
    "No vamos a ver su detalle matemático. Las herramientas lo traen implementado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Hay que decidir unas cuantas cosas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cuántas **capas**? Cuántas **neuronas** en cada capa? Cómo son las **conexiones** entre capas?\n",
    "\n",
    "Esto se llama \"Arquitectura\" de nuestra red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pregunta difícil de responder: depende del caso, mirar cosas que hizo otra gente, etc.\n",
    "\n",
    "* Pocas? Podemos no lograr buen resultado.\n",
    "* Muchas? Podemos sobreentrenar, y puede ser muy lento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Qué función de **activación** en cada capa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lo habitual es:\n",
    "\n",
    "* Relu, Tanh o Sigmoidea en capas intermedias.\n",
    "* Sigmoidea en capa de salida de redes con una sola salida entre 0 y 1.\n",
    "* Softmax en capa de salida de redes con N salidas entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Qué variante de **decenso por el gradiente**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Normalmente \"adam\" anda bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Qué variante de función de **error**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lo habitual es:\n",
    "\n",
    "* Binary_crossentropy para redes con una sola salida entre 0 y 1.\n",
    "* Categorical_crossentropy para redes con N salidas entre 0 y 1.\n",
    "\n",
    "A veces puede hacer falta configurar \"pesos\" para los errores positivos y negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Y algunos consejos más\n",
    "\n",
    "* Normalizar las entradas.\n",
    "* Como siempre, entrenar y testear con sets separados. Las redes neuronales pueden overfitear muy fácil!\n",
    "* Probar cambios de a **una** cosa a la vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Técnica relacionada útil: dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/dropout.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Capa que \"apaga\" conexiónes de forma aleatoria.\n",
    "\n",
    "\n",
    "**Para qué?**\n",
    "\n",
    "Para evitar que cada capa se \"memorice\" resultados que tiene que dar para determinados inputs (overfit interno y de la red en general)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Zoológico de redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "MLP es el tipo más común, pero hay **muchas** otras formas de neuronas.\n",
    "\n",
    "Principalmente lo que cambia es la **arquitectura de la red**, la forma en la que las neuronas están conectadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/zoo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Muy buen resumen de la utilidad de cada arquitectura!:\n",
    "\n",
    "[THE NEURAL NETWORK ZOO](http://www.asimovinstitute.org/neural-network-zoo/)\n",
    "\n",
    "Nosotros vamos a ver un poco de 3 de ellas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Esto es un poco loco..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/autoencoders.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenamos usando las entradas también como salidas! \n",
    "\n",
    "Ej: \n",
    "\n",
    "entrada=`[\"fisa\", 30, \"espadas\"]`\n",
    "\n",
    "salida=`[\"fisa\", 30, \"espadas\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Como la red se **achica en el medio**, entonces tiene que **comprimir la información de entrada** de alguna forma, para que termine siendo expresada en menos números.\n",
    "\n",
    "Pero como luego desde esos pocos números tiene que volver a generar las salidas originales, tiene que poder **descomprimir la información comprimida**.\n",
    "\n",
    "Termina aprendiendo dos redes juntas: una que **comprime** información, y otra que la **descomprime**... Nuestro propio algoritmo de compresión! \n",
    "\n",
    "Inentendible, pero que quizás funciona mejor para nnuestro problema, que los algoritmos genéricos de compresión.\n",
    "\n",
    "También se puede usar para **reducir dimensionalidad** de un set de datos (para visualizarlo, dárselo a modelos más simples, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Esto es **muy** loco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/transfer_style.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/pix2pix_face.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/obama_hilary.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_resolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_refill.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_objects.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "No?\n",
    "\n",
    "![](files/images/gan_faces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cómo funcionan???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/gans.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La red **discriminadora** intenta predecir correctamente si sus entradas son un ejemplo real o un ejemplo generado.\n",
    "\n",
    "La red **generadora** trata de generar ejemplos que confundan a la red discriminadora, a partir de entradas (que pueden ser random, o algún tipo de dato relacionado. Ej: dibujo a mano)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Primero entrenamos un poco la red **discriminadora**, hasta que sepa reconocer bien la cosa que queremos generar después (ej: fotos de perros vs fotos de no-perros).\n",
    "\n",
    "Luego empezamos a generar ejemplos con la **generadora**, y se los pasamos a la **discriminadora**. Cuanto mejor prediga la discriminadora, **más error** le devolvemos a la generadora.\n",
    "\n",
    "Seguimos entrenando ambas redes **a la vez**, que a partir de ahora **compiten** (una por detectar bien perros reales, la otra por generar perros que parezcan reales)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MAGIA\n",
    "\n",
    "![](files/images/magic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Esto es **muy** efectivo principalmente cuando las entradas son imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/image.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Cómo le damos eso como entrada a una red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/image_as_input.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Esto presenta 2 grandes problemas:\n",
    "\n",
    "* La gran cantidad de parámetros\n",
    "* Hay información espacial compartida y no se saca provecho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gran cantidad de parámetros\n",
    "\n",
    "* Si suponemos imagenes de 227x227x3, **cada neurona** tendría 154.588 pesos para aprender\n",
    "* La solución es conectar las neuronas con una **porción** de la imagen de entrada\n",
    " * Por ejemplo, si cada neurona se conecta con una porción de 11x11, los pesos de esa neurona serían solo 364  \n",
    "* La porción de 11x11 (por la profundidad) se la conoce como **filtro**\n",
    "* Al convolucionar un filtro sobre la imagen de entrada obtenemos un **feature map**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](files/images/conv_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Información espacial compartida\n",
    "\n",
    "* Hay patrones que se repiten, sin importar la posición. Por ej, detectar lineas verticales.\n",
    "* Una solución a esto es reusar los pesos para cada una de las neuronas que pertenecen al mismo filtro\n",
    "\n",
    "Este hecho vuelve a reducir el número de parametros. Siguiendo el ejemplo anterior y suponiendo 100 neuronas de salida, organizadas en 10 filtros, sin compartir pesos tendriamos 36.400 pesos. \n",
    "\n",
    "Compartiendo los parámetros nos quedamos con solo 3.640 pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Parámetros y conceptos más comunes\n",
    "\n",
    "* **Input size W**: el tamaño de la entrada\n",
    "* **filters:** cantidad de filtros \n",
    "* **kernel_size F:** tamaño del kernel; se establece el ancho y alto, la profundidad depende de las entradas\n",
    "* **strides S:** la cantidad de pasos que muevo el kernel\n",
    "* **padding P:** agrega ceros en los bordes para mantener el tamaño original\n",
    "* **activation:** función de activación aplicada ``pixel a pixel``\n",
    "\n",
    "La cantidad de neuronas de salida es **(W - F + 2P)/S + 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En algún momento, aplanamos la disposición de las neuronas para obtener un vector y continuar con aun red full connected convencional.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](files/images/neural_network_complete.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Las convoluciones pueden terminar aprendiendo **\"features\"** de la imagen **de a poco**, desde conceptos más simples a más complejos.\n",
    "\n",
    "Ej: primer convolución reconoce tipo de terreno en base a pixeles (planta, agua, cemento, arena). La siguiente convolución reconoce ciudad/playa/bosque/desierto en base a los tipos de terreno y su posición en la salida de la capa anterior (ej: agua + arena = playa). La siguiente convolución reconoce la región del país, en base a cuántas playas, bosques, ciudades, etc ve en las salidas de la anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Son **muy** efectivas para clasificación de imágenes. El estándar hoy en día.\n",
    "* Son muy pesadas de calcular.\n",
    "* Implica determinar cosas nuevas: qué tamaño tienen los kernels, cuántas convoluciones, etc.\n",
    "* Se suele utilizar otra operación llamada **Pooling**, para ir reduciendo el tamaño de los features maps. Opera sobre kernels, pero:\n",
    " * Toma el valor máximo (o el promedio) de las entradas. No hay aprendizaje\n",
    " * Trabaja de forma independiente en cada profundidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Deep learning?\n",
    "\n",
    "*The hierarchy of concepts enables the computer to learn complicated concepts bybuilding them out of simpler ones. If we draw a graph showing how these concepts are built on top of each other, the graph is deep, with many layers. For this reason,we call this approach to AI deep learning.*\n",
    "\n",
    "\n",
    "**Goodfellow et al 2016**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
